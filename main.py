import streamlit as st
import boto3
import base64
import hashlib
import os
import json
import re
from typing import List
from datetime import datetime
from models import SpanishVocabulary, ImageVocabularyResponse
from db import SessionLocal
from models_db import User, Image, VocabularyEntry
from sqlalchemy.orm import Session
from timeline import TimelineEntry, get_timeline_entries

bedrock = boto3.client(
    service_name='bedrock-runtime',
    region_name='us-east-1',
    aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"],
    aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"]
)

def encode_image_data(image_data):
    """
    Encode image data to base64.
    
    Args:
        image_data: Binary image data from uploaded file
        
    Returns:
        str: Base64 encoded image data
    """
    return base64.b64encode(image_data).decode('utf-8')

def analyze_image_core(image_data: bytes) -> List[SpanishVocabulary]:
    """
    Core function to analyze image using Claude Haiku via AWS Bedrock.
    This function is independent of any UI framework.
    
    Args:
        image_data: Binary image data
        
    Returns:
        list[SpanishVocabulary]: A list of Spanish vocabulary words found in the image
        
    Raises:
        ValueError: If structured data parsing fails
        TimeoutError: If the request times out
        Exception: For any other unexpected errors
    """
    base64_image = encode_image_data(image_data)
    
    prompt = """
ä¸Šè¨˜ã®å†™çœŸã‚’ã‚¹ãƒšã‚¤ãƒ³èªã§è¡¨ç¾ã—ãŸã„ã¨ã„ã†ã‚¹ãƒšã‚¤ãƒ³èªå­¦ç¿’è€…ãŒã„ã¾ã™ã€‚

ã‚ãªãŸã¯ä¸Šè¨˜ã®ç”»åƒã«å†™ã£ã¦ã„ã‚‹çŠ¶æ³ã‚’èª¬æ˜ã™ã‚‹ã®ã«å¿…è¦ãªã‚¹ãƒšã‚¤ãƒ³èªã®å˜èªã‚„è¡¨ç¾ã®ãƒªã‚¹ãƒˆã‚’ä½œã£ã¦ã‚ã’ã¦ãã ã•ã„ã€‚ä¸Šè¨˜ã®å†™çœŸã«å†™ã£ã¦ã„ã‚‹ã‚‚ã®ã®åå‰ãªã©ã‚’ã€ã‚¹ãƒšã‚¤ãƒ³èªãƒ»å“è©ãƒ»æ—¥æœ¬èªãƒ»ã‚¹ãƒšã‚¤ãƒ³èªä¾‹æ–‡ã®ï¼”ã¤ã®ãƒ‡ãƒ¼ã‚¿ã®ã‚»ãƒƒãƒˆã¨ã—ã¦åˆ—æŒ™ã—ã¦ã»ã—ã„ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿æ§‹æˆã§ãƒªã‚¹ãƒˆã‚’ä½œã£ã¦ãã ã•ã„ã€‚(é…åˆ—ã®ä¸­ã«ã€ã•ã‚‰ã«ï¼”ã¤ã®å±æ€§ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½œã£ã¦ãã ã•ã„ã€‚)
{
    "vocabulary": [{
        "word": "ã‚¹ãƒšã‚¤ãƒ³èªã®å˜èª",
        "part_of_speech": "å“è©ï¼ˆå¿…ãšã€Œåè©ã€ã€Œå‹•è©ã€ã€Œå½¢å®¹è©ã€ã€Œå‰¯è©ã€ã®ãªã©ã‚’æŒ‡å®šï¼‰",
        "translation": "æ—¥æœ¬èªè¨³",
        "example_sentence": "ãã®å˜èªã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒšã‚¤ãƒ³èªã®ä¾‹æ–‡ï¼ˆå¿…ãšå®Œå…¨ãªæ–‡ã‚’è¨˜è¼‰ï¼‰"
    }]
}

é‡è¦ãªæ³¨æ„ç‚¹ï¼š
1. å„å˜èªã«ã¤ã„ã¦ã€å¿…ãš4ã¤ã®æƒ…å ±ï¼ˆword, part_of_speech, translation, example_sentenceï¼‰ã‚’å«ã‚ã¦ãã ã•ã„
2. ä¾‹æ–‡ã¯å¿…ãšå®Œå…¨ãªæ–‡ã§è¨˜è¼‰ã—ã¦ãã ã•ã„
3. JSONã®å½¢å¼ã‚’å³å¯†ã«å®ˆã£ã¦ãã ã•ã„
"""
    
    try:
        response = bedrock.invoke_model(
            modelId="anthropic.claude-3-haiku-20240307-v1:0",
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 1000,
                "temperature": 0,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/jpeg",
                                    "data": base64_image
                                }
                            },
                            {
                                "type": "text",
                                "text": prompt
                            }
                        ]
                    }
                ]
            })
        )
        
        response_body = json.loads(response.get('body').read())
        response_text = response_body['content'][0]['text']
        
        # Extract JSON from response
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if not json_match:
            raise ValueError("No JSON found in response")
            
        json_str = json_match.group()
        data = json.loads(json_str)
        
        # Convert to SpanishVocabulary objects
        vocab_list = []
        for item in data.get("vocabulary", []):
            vocab = SpanishVocabulary(
                word=item["word"],
                part_of_speech=item["part_of_speech"],
                translation=item["translation"],
                example_sentence=item["example_sentence"]
            )
            vocab_list.append(vocab)
        
        return vocab_list
    except Exception as e:
        st.error(f"ç”»åƒåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise

def analyze_image(image_data: bytes) -> list[SpanishVocabulary]:
    """
    Analyze image using Google's Gemini model via Langchain.
    This function wraps analyze_image_core with Streamlit UI feedback.
    
    Args:
        image_data: Binary image data from uploaded file
        
    Returns:
        list[SpanishVocabulary]: A list of Spanish vocabulary words found in the image
    """
    try:
        vocab = analyze_image_core(image_data)
        if not vocab:
            st.warning("ç”»åƒã‹ã‚‰å˜èªã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ç”»åƒã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
        return vocab
    except ValueError as e:
        st.error("æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        return []
    except TimeoutError as e:
        st.error("ç”»åƒè§£æãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        return []
    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def get_or_create_user(db: Session, username: str = "test_user") -> User:
    """Get or create a test user for development."""
    user = db.query(User).filter(User.username == username).first()
    if not user:
        user = User(username=username)
        db.add(user)
        db.commit()
        db.refresh(user)
    return user

def save_image(db: Session, user_id: int, image_data: bytes) -> Image:
    """Save uploaded image to database."""
    try:
        image = Image(user_id=user_id, image_data=image_data)
        db.add(image)
        db.commit()
        db.refresh(image)
        return image
    except Exception as e:
        db.rollback()
        st.error(f"ç”»åƒã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise

def save_vocabulary(db: Session, user_id: int, image_id: int, vocab_items: List[SpanishVocabulary]):
    """Save vocabulary entries to database."""
    try:
        for item in vocab_items:
            vocab_entry = VocabularyEntry(
                user_id=user_id,
                image_id=image_id,
                spanish_word=item.word,
                part_of_speech=item.part_of_speech,
                japanese_translation=item.translation,
                example_sentence=item.example_sentence
            )
            db.add(vocab_entry)
        db.commit()
    except Exception as e:
        db.rollback()
        st.error(f"å˜èªã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise

def main():
    """
    Main function for the Photoword application.
    Provides a simple interface for uploading photos and analyzing them for Spanish vocabulary.
    """
    st.title("Photoword - ã‚¹ãƒšã‚¤ãƒ³èªå˜èªå¸³")
    st.subheader("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å˜èªå¸³ã‚’ä½œæˆ")
    
    # Initialize session state for tracking processed images
    if "processed_image_hash" not in st.session_state:
        st.session_state.processed_image_hash = None
    
    # Initialize database session
    db = SessionLocal()
    try:
        # Get or create test user
        user = get_or_create_user(db)
        
        # File uploader widget
        uploaded_file = st.file_uploader(
            "å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=["jpg", "jpeg", "png"],
            help="JPGã€JPEGã€ã¾ãŸã¯PNGå½¢å¼ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )
        
        # Display uploaded image and analyze
        if uploaded_file is not None:
            image_data = uploaded_file.getvalue()
            current_hash = hashlib.md5(image_data).hexdigest()
            # Only process if this image hash is different from the last processed
            if st.session_state.processed_image_hash != current_hash:
                st.image(uploaded_file, use_container_width=True)
                vocab_list = analyze_image(image_data)
                
                if vocab_list:
                    # Save image and vocabulary to database
                    image = save_image(db, user.id, image_data)
                    save_vocabulary(db, user.id, image.id, vocab_list)
                    # Mark as processed
                    st.session_state.processed_image_hash = current_hash
                    # Clear file uploader by triggering a rerun
                    st.rerun()
                else:
                    st.write("å˜èªã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.warning("ã“ã®ç”»åƒã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™ã€‚")
        
        # Display timeline entries with styling
        st.markdown("## ğŸ“¸ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")
        
        # Initialize session state for filters
        if "search_term" not in st.session_state:
            st.session_state.search_term = ""
        if "start_date" not in st.session_state:
            st.session_state.start_date = None
        if "end_date" not in st.session_state:
            st.session_state.end_date = None
        if "page_size" not in st.session_state:
            st.session_state.page_size = 5
        if "page_number" not in st.session_state:
            st.session_state.page_number = 1

        # Add search and date filter widgets with better styling
        st.markdown("### ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
        filter_container = st.container()
        with filter_container:
            # Add search input
            st.text_input(
                "å˜èªæ¤œç´¢ (ã‚¹ãƒšã‚¤ãƒ³èªã¾ãŸã¯æ—¥æœ¬èª)",
                placeholder="æ¤œç´¢ã—ãŸã„å˜èªã‚’å…¥åŠ›...",
                key="search_term"
            )
            
            # Date range filters
            col1, col2 = st.columns(2)
            with col1:
                st.date_input(
                    "é–‹å§‹æ—¥",
                    key="start_date"
                )
            with col2:
                st.date_input(
                    "çµ‚äº†æ—¥",
                    key="end_date"
                )
        
        # Add pagination controls with better styling
        st.markdown("### ğŸ“„ ãƒšãƒ¼ã‚¸è¨­å®š")
        pagination_container = st.container()
        with pagination_container:
            col1, col2 = st.columns([1, 3])
            with col1:
                st.selectbox(
                    "è¡¨ç¤ºä»¶æ•°",
                    options=[5, 10, 20],
                    key="page_size"
                )
            with col2:
                st.number_input(
                    "ãƒšãƒ¼ã‚¸ç•ªå·",
                    min_value=1,
                    step=1,
                    key="page_number"
                )
        skip = (st.session_state.page_number - 1) * st.session_state.page_size
        
        # Get timeline entries with search
        timeline_entries = get_timeline_entries(
            db,
            user.id,
            skip=skip,
            limit=st.session_state.page_size,
            start_date=st.session_state.start_date if st.session_state.start_date else None,
            end_date=st.session_state.end_date if st.session_state.end_date else None,
            search_term=st.session_state.search_term if st.session_state.search_term else None
        )
        
        # Initialize detail view state
        if "show_detail" not in st.session_state:
            st.session_state["show_detail"] = None

        # Display timeline entries with improved styling
        if timeline_entries:
            for entry in timeline_entries:
                with st.expander(
                    f"ğŸ“¸ {entry.created_at.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}",
                    expanded=True
                ):
                    # Create columns for image, vocabulary, and detail button
                    img_col, vocab_col, btn_col = st.columns([2, 3, 1])
                    
                    # Display image in left column
                    with img_col:
                        st.image(entry.image_data, use_container_width=True)
                    
                    # Display vocabulary items in middle column
                    with vocab_col:
                        for vocab in entry.vocabulary_entries:
                            markdown_text = f"""
                            ### {vocab.spanish_word}
                            - ğŸ“š [{vocab.part_of_speech}] {vocab.japanese_translation}
                            - ğŸ’­ {vocab.example_sentence}
                            ---
                            """
                            st.markdown(markdown_text)
                    
                    # Add detail view button in right column
                    with btn_col:
                        if st.button("è©³ç´°ã‚’è¡¨ç¤º", key=f"detail_btn_{entry.id}"):
                            st.session_state["show_detail"] = entry.id
                
                # Show detail modal if this entry is selected
                if st.session_state["show_detail"] == entry.id:
                    with st.container():
                        st.markdown("---")
                        st.markdown("## ğŸ“ è©³ç´°è¡¨ç¤º")
                        
                        # Display full-size image
                        st.image(entry.image_data, use_container_width=True)
                        
                        # Display comprehensive vocabulary information
                        st.markdown("### ğŸ“š å˜èªãƒªã‚¹ãƒˆ")
                        for vocab in entry.vocabulary_entries:
                            st.markdown(f"""
                            #### {vocab.spanish_word}
                            - **å“è©**: {vocab.part_of_speech}
                            - **æ—¥æœ¬èª**: {vocab.japanese_translation}
                            - **ä¾‹æ–‡**: {vocab.example_sentence}
                            """)
                        
                        # Add close button
                        if st.button("é–‰ã˜ã‚‹", key=f"close_btn_{entry.id}"):
                            st.session_state["show_detail"] = None
                        st.markdown("---")
        else:
            st.info("è¡¨ç¤ºã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–°ã—ã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise


if __name__ == "__main__":
    try:
        main()
    finally:
        # Ensure database session is closed
        if 'db' in locals():
            db.close()
