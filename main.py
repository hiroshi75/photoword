import streamlit as st
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage
import base64
import os
from typing import List
from datetime import datetime
from models import SpanishVocabulary, ImageVocabularyResponse
from db import SessionLocal
from models_db import User, Image, VocabularyEntry
from sqlalchemy.orm import Session
from timeline import TimelineEntry, get_timeline_entries

def encode_image_data(image_data):
    """
    Encode image data to base64.
    
    Args:
        image_data: Binary image data from uploaded file
        
    Returns:
        str: Base64 encoded image data
    """
    return base64.b64encode(image_data).decode('utf-8')

def analyze_image_core(image_data: bytes) -> List[SpanishVocabulary]:
    """
    Core function to analyze image using Google's Gemini model via Langchain.
    This function is independent of any UI framework.
    
    Args:
        image_data: Binary image data
        
    Returns:
        list[SpanishVocabulary]: A list of Spanish vocabulary words found in the image
        
    Raises:
        ValueError: If structured data parsing fails
        TimeoutError: If the request times out
        Exception: For any other unexpected errors
    """
    base64_image = encode_image_data(image_data)
    
    chat = ChatBedrock(
        aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"],
        aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"],
        model_id="anthropic.claude-3-haiku-20240307-v1:0",
        region_name="us-east-1",
        model_kwargs=dict(temperature=0)
    )
    
    human_template = """
ä¸Šè¨˜ã®å†™çœŸã‚’ã‚¹ãƒšã‚¤ãƒ³èªã§è¡¨ç¾ã—ãŸã„ã¨ã„ã†ã‚¹ãƒšã‚¤ãƒ³èªå­¦ç¿’è€…ãŒã„ã¾ã™ã€‚

ã‚ãªãŸã¯ä¸Šè¨˜ã®ç”»åƒã«å†™ã£ã¦ã„ã‚‹çŠ¶æ³ã‚’èª¬æ˜ã™ã‚‹ã®ã«å¿…è¦ãªã‚¹ãƒšã‚¤ãƒ³èªã®å˜èªã‚„è¡¨ç¾ã®ãƒªã‚¹ãƒˆã‚’ä½œã£ã¦ã‚ã’ã¦ãã ã•ã„ã€‚ä¸Šè¨˜ã®å†™çœŸã«å†™ã£ã¦ã„ã‚‹ã‚‚ã®ã®åå‰ãªã©ã‚’ã€ã‚¹ãƒšã‚¤ãƒ³èªãƒ»å“è©ãƒ»æ—¥æœ¬èªãƒ»ã‚¹ãƒšã‚¤ãƒ³èªä¾‹æ–‡ã®ï¼”ã¤ã®ãƒ‡ãƒ¼ã‚¿ã®ã‚»ãƒƒãƒˆã¨ã—ã¦åˆ—æŒ™ã—ã¦ã»ã—ã„ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿æ§‹æˆã§ãƒªã‚¹ãƒˆã‚’ä½œã£ã¦ãã ã•ã„ã€‚(é…åˆ—ã®ä¸­ã«ã€ã•ã‚‰ã«ï¼”ã¤ã®å±æ€§ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½œã£ã¦ãã ã•ã„ã€‚)
{
    vocabulary: [{
        word: ã‚¹ãƒšã‚¤ãƒ³èªã®å˜èª
        part_of_speech: å“è©ï¼ˆå¿…ãšã€Œåè©ã€ã€Œå‹•è©ã€ã€Œå½¢å®¹è©ã€ã€Œå‰¯è©ã€ã®ãªã©ã‚’æŒ‡å®šï¼‰
        translation: æ—¥æœ¬èªè¨³
        example_sentence: ãã®å˜èªã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒšã‚¤ãƒ³èªã®ä¾‹æ–‡ï¼ˆå¿…ãšå®Œå…¨ãªæ–‡ã‚’è¨˜è¼‰ï¼‰
    }, ...] //å˜èªæ•°åˆ†ç¹°ã‚Šè¿”ã™
}

é‡è¦ãªæ³¨æ„ç‚¹ï¼š
1. å„å˜èªã«ã¤ã„ã¦ã€å¿…ãš4ã¤ã®æƒ…å ±ï¼ˆword, part_of_speech, translation, example_sentence
2. ä¾‹æ–‡ã¯å¿…ãšå®Œå…¨ãªæ–‡ã§è¨˜è¼‰ã—ã¦ãã ã•ã„
"""

    human_message = HumanMessage(content=[
        
        {
            "type": "image_url", 
            "image_url": {
                "url": f"data:image/png;base64,{base64_image}"
            }
        },
        {
            "type":"text",
            "text":human_template
        }
    ])
    prompt = ChatPromptTemplate.from_messages([
        human_message
    ])
    structured_chat = chat.with_structured_output(ImageVocabularyResponse)
    chain = prompt | structured_chat
    
    result = chain.invoke({})
    print(result)
    
    if not result or not result.vocabulary:
        return []
        
    return result.vocabulary  # Returns List[SpanishVocabulary]

def analyze_image(image_data: bytes) -> list[SpanishVocabulary]:
    """
    Analyze image using Google's Gemini model via Langchain.
    This function wraps analyze_image_core with Streamlit UI feedback.
    
    Args:
        image_data: Binary image data from uploaded file
        
    Returns:
        list[SpanishVocabulary]: A list of Spanish vocabulary words found in the image
    """
    try:
        vocab = analyze_image_core(image_data)
        if not vocab:
            st.warning("ç”»åƒã‹ã‚‰å˜èªã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ç”»åƒã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
        return vocab
    except ValueError as e:
        st.error("æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        return []
    except TimeoutError as e:
        st.error("ç”»åƒè§£æãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        return []
    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def get_or_create_user(db: Session, username: str = "test_user") -> User:
    """Get or create a test user for development."""
    user = db.query(User).filter(User.username == username).first()
    if not user:
        user = User(username=username)
        db.add(user)
        db.commit()
        db.refresh(user)
    return user

def save_image(db: Session, user_id: int, image_data: bytes) -> Image:
    """Save uploaded image to database."""
    try:
        image = Image(user_id=user_id, image_data=image_data)
        db.add(image)
        db.commit()
        db.refresh(image)
        return image
    except Exception as e:
        db.rollback()
        st.error(f"ç”»åƒã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise

def save_vocabulary(db: Session, user_id: int, image_id: int, vocab_items: List[SpanishVocabulary]):
    """Save vocabulary entries to database."""
    try:
        for item in vocab_items:
            vocab_entry = VocabularyEntry(
                user_id=user_id,
                image_id=image_id,
                spanish_word=item.word,
                part_of_speech=item.part_of_speech,
                japanese_translation=item.translation,
                example_sentence=item.example_sentence
            )
            db.add(vocab_entry)
        db.commit()
    except Exception as e:
        db.rollback()
        st.error(f"å˜èªã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise

def main():
    """
    Main function for the Photoword application.
    Provides a simple interface for uploading photos and analyzing them for Spanish vocabulary.
    """
    st.title("Photoword - ã‚¹ãƒšã‚¤ãƒ³èªå˜èªå¸³")
    st.subheader("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å˜èªå¸³ã‚’ä½œæˆ")
    
    # Initialize database session
    db = SessionLocal()
    try:
        # Get or create test user
        user = get_or_create_user(db)
        
        # File uploader widget
        uploaded_file = st.file_uploader(
            "å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=["jpg", "jpeg", "png"],
            help="JPGã€JPEGã€ã¾ãŸã¯PNGå½¢å¼ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )
        
        # Display uploaded image and analyze
        if uploaded_file is not None:
            image_data = uploaded_file.getvalue()
            st.image(uploaded_file)
            vocab_list = analyze_image(image_data)
            
            if vocab_list:
                # Save image and vocabulary to database
                image = save_image(db, user.id, image_data)
                save_vocabulary(db, user.id, image.id, vocab_list)
            else:
                st.write("å˜èªã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # Display timeline entries with styling
        st.markdown("## ğŸ“¸ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")
        
        # Add search and date filter widgets with better styling
        st.markdown("### ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
        filter_container = st.container()
        with filter_container:
            # Add search input
            if "search_term" not in st.session_state:
                st.session_state["search_term"] = ""
            search_term = st.text_input(
                "å˜èªæ¤œç´¢ (ã‚¹ãƒšã‚¤ãƒ³èªã¾ãŸã¯æ—¥æœ¬èª)",
                value=st.session_state["search_term"],
                placeholder="æ¤œç´¢ã—ãŸã„å˜èªã‚’å…¥åŠ›...",
                key="search_input"
            )
            st.session_state["search_term"] = search_term
            
            # Date range filters
            col1, col2 = st.columns(2)
            with col1:
                start_date = st.date_input("é–‹å§‹æ—¥", value=None, key="start_date")
            with col2:
                end_date = st.date_input("çµ‚äº†æ—¥", value=None, key="end_date")
        
        # Add pagination controls with better styling
        st.markdown("### ğŸ“„ ãƒšãƒ¼ã‚¸è¨­å®š")
        pagination_container = st.container()
        with pagination_container:
            col1, col2 = st.columns([1, 3])
            with col1:
                page_size = st.selectbox(
                    "è¡¨ç¤ºä»¶æ•°",
                    options=[5, 10, 20],
                    index=0,
                    key="page_size"
                )
            with col2:
                page_number = st.number_input(
                    "ãƒšãƒ¼ã‚¸ç•ªå·",
                    min_value=1,
                    value=1,
                    step=1,
                    key="page_number"
                )
        skip = (page_number - 1) * page_size
        
        # Get timeline entries with search
        timeline_entries = get_timeline_entries(
            db,
            user.id,
            skip=skip,
            limit=page_size,
            start_date=start_date if start_date else None,
            end_date=end_date if end_date else None,
            search_term=search_term if search_term else None
        )
        
        # Display timeline entries with improved styling
        if timeline_entries:
            for entry in timeline_entries:
                with st.expander(
                    f"ğŸ“¸ {entry.created_at.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}",
                    expanded=True
                ):
                    # Create columns for image and vocabulary
                    img_col, vocab_col = st.columns([2, 3])
                    
                    # Display image in left column
                    with img_col:
                        st.image(entry.image_data, use_container_width=True)
                    
                    # Display vocabulary items in right column
                    with vocab_col:
                        for vocab in entry.vocabulary_entries:
                            markdown_text = f"""
                            ### {vocab.spanish_word}
                            - ğŸ“š [{vocab.part_of_speech}] {vocab.japanese_translation}
                            - ğŸ’­ {vocab.example_sentence}
                            ---
                            """
                            st.markdown(markdown_text)
        else:
            st.info("è¡¨ç¤ºã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–°ã—ã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise


if __name__ == "__main__":
    try:
        main()
    finally:
        # Ensure database session is closed
        if 'db' in locals():
            db.close()
